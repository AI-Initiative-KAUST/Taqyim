{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(sample = 0, task = '', version = 3, dataset = 'padt'):\n",
    "    if version == 3:\n",
    "        record_path = f'eval_results/eval_results_gpt_3_5/zero_shot/{dataset}.jsonl'\n",
    "    else:\n",
    "        record_path = f'eval_results/eval_results_gpt_4_0/zero_shot/{dataset}.jsonl'\n",
    "    \n",
    "    prompts = []\n",
    "    samples = []\n",
    "    with open(record_path, \"r\") as f:\n",
    "        events_df = pd.read_json(f, lines=True)\n",
    "    \n",
    "    sampling = events_df[events_df.type == \"sampling\"].sort_values('sample_id')\n",
    "\n",
    "    df = pd.json_normalize(sampling.data)\n",
    "    \n",
    "    for i, r in df.iterrows():\n",
    "        prompts.append(r.prompt[-1]['content'])    \n",
    "        samples.append(r.sampled)\n",
    "    \n",
    "    out = samples[sample]\n",
    "    inp = prompts[sample]\n",
    "    if task == 'pos':\n",
    "        out = [s.split(':')[:2] for s in out.split('\\n')]\n",
    "        out = '\\n'.join(['\\\\RL{'+token+'}:'+tag for (token, tag) in out])\n",
    "    \n",
    "    if task == 'sum':\n",
    "        inp = inp[:50]+ ' ... '\n",
    "        out = out[:50]+ ' ... '    \n",
    "    return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  [{'role': 'system', 'content': 'I wish you can...   \n",
      "1  [{'role': 'system', 'content': 'I wish you can...   \n",
      "2  [{'role': 'system', 'content': 'I wish you can...   \n",
      "3  [{'role': 'system', 'content': 'I wish you can...   \n",
      "4  [{'role': 'system', 'content': 'I wish you can...   \n",
      "\n",
      "                                             sampled  \\\n",
      "0  سوريا:NOUN\\n: :PUNCT\\nتعديل:NOUN\\nوزاري:ADJ\\nو...   \n",
      "1  و:CCONJ\\nذكرت:VERB\\nوكالة:NOUN\\nالانباء:NOUN\\n...   \n",
      "2  و:CCONJ\\nعين:NOUN\\nاللواء:NOUN\\nكنعان:PROPN\\nا...   \n",
      "3  و:CCONJ\\nكان:AUX\\nكنعان:PROPN\\nقبل:ADP\\nذلك:PR...   \n",
      "4  و: CCONJ\\nفي: ADP\\nما: PRON\\nي: PRON\\nلي: VERB...   \n",
      "\n",
      "                   metadata.completion_id      metadata.model  \n",
      "0  chatcmpl-7FGIhvFm6ZVytO7OORpXzShHbRYlN  gpt-3.5-turbo-0301  \n",
      "1  chatcmpl-7FGIhUT2SrAKym86g0y47YZX5DmaM  gpt-3.5-turbo-0301  \n",
      "2  chatcmpl-7FGIhg6AH5IBAH0pNSbcXxzRWmpTP  gpt-3.5-turbo-0301  \n",
      "3  chatcmpl-7FGImM55EXerauAGpcLPYj1IZZnTO  gpt-3.5-turbo-0301  \n",
      "4  chatcmpl-7FGIrykxnxKee8YWN9MVozwl9ee68  gpt-3.5-turbo-0301  \n",
      "\n",
      "\\makecell{\n",
      "\\RL{سوريا : تعديل وزاري واسع يشمل 8 حقائب} \\\\\n",
      "\\hline\n",
      "\\RL{\\RL{سوريا}:NOUN\n",
      "\\RL{}: \n",
      "\\RL{تعديل}:NOUN\n",
      "\\RL{وزاري}:ADJ\n",
      "\\RL{واسع}:ADJ\n",
      "\\RL{يشمل}:VERB\n",
      "\\RL{8}:NUM\n",
      "\\RL{حقائب}:NOUN}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input, output = show_results(version = 3,\n",
    "                             sample = 0,\n",
    "                             task = 'pos',\n",
    "                             dataset = 'padt')\n",
    "\n",
    "line_sep = \" \\\\\\ \"\n",
    "results  = '''\n",
    "\\makecell{\n",
    "\\RL{'''+input+'''} \\\\\\\\\n",
    "\\\\hline\n",
    "\\RL{'''+output+'''}\n",
    "}\n",
    "'''\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\makecell{\n",
      "\\RL{الجلسة 7439 المعقودة في 11 أيار/مايو ٢٠١٥.} \\\\\n",
      "\\hline\n",
      "\\RL{Session 7439 held on May 11, 2015.}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input, output = show_results(version = 4,\n",
    "                             dataset = 'unv1',\n",
    "                             sample = 0)\n",
    "line_sep = \" \\\\\\ \"\n",
    "results  = '''\n",
    "\\makecell{\n",
    "\\RL{'''+input+'''} \\\\\\\\\n",
    "\\\\hline\n",
    "\\RL{'''+output+'''}\n",
    "}\n",
    "'''\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\makecell{\n",
      "\\RL{﻿لودفيج فان بيتهوفن مؤلف موسيقي ألماني ولد عام 177 ... } \\\\\n",
      "\\hline\n",
      "\\RL{لودفيج فان بيتهوفن هو مؤلف موسيقي ألماني ولد في بو ... }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input, output = show_results(version = 3,\n",
    "                             dataset = 'easc',\n",
    "                             sample = 0,\n",
    "                             task = 'sum')\n",
    "line_sep = \" \\\\\\ \"\n",
    "results  = '''\n",
    "\\makecell{\n",
    "\\RL{'''+input+'''} \\\\\\\\\n",
    "\\\\hline\n",
    "\\RL{'''+output+'''}\n",
    "}\n",
    "'''\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calculate_output_length(version = 3, dataset = 'padt'):\n",
    "    if version == 3:\n",
    "        record_path = f'eval_results/eval_results_gpt_3_5/zero_shot/{dataset}.jsonl'\n",
    "    else:\n",
    "        record_path = f'eval_results/eval_results_gpt_4_0/zero_shot/{dataset}.jsonl'\n",
    "    \n",
    "    prompts = []\n",
    "    samples = []\n",
    "    with open(record_path, \"r\") as f:\n",
    "        events_df = pd.read_json(f, lines=True)\n",
    "    \n",
    "    sampling = events_df[events_df.type == \"sampling\"].sort_values('sample_id')\n",
    "\n",
    "    df = pd.json_normalize(sampling.data)\n",
    "    \n",
    "    for i, r in df.iterrows():\n",
    "        prompts.append(r.prompt[-1]['content'])    \n",
    "        samples.append(r.sampled)\n",
    "    \n",
    "    \n",
    "    len_samples = [len(sample) for sample in samples] \n",
    "    return sum(len_samples)/len(len_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429.01960784313724"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_output_length(version = 3, dataset = 'easc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347.51612903225805"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_output_length(version = 4, dataset = 'easc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
